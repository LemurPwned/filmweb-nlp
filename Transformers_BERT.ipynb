{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LemurPwned/filmweb-nlp/blob/master/Transformers_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91gigFqrlFzu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0lfw5T-kjlz",
        "colab_type": "code",
        "outputId": "7ce6311f-5a53-4f96-f8b3-55f44f9ddce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 43.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 33.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.4 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.4->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.4->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=65f03410567e4327f04db97c3063efa45f1c77bac779f7f45957981926762ce9\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: regex, sacremoses, sentencepiece, transformers\n",
            "Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY_hw-16kXkq",
        "colab_type": "code",
        "outputId": "5bb613cd-ec42-4741-8c92-f483f0eca202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "import pandas as pd \n",
        "from transformers import BertForSequenceClassification,BertTokenizer\n",
        "model_name = 'bert-base-multilingual-cased'\n",
        "\n",
        "df = pd.read_csv('/content/reviews_for_bert.csv')\n",
        "labels = df['rating'].unique().tolist()\n",
        "if 0 not in labels:\n",
        "  # labels must start from 0\n",
        "  labels = [label - 1 for label in labels]\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name,\n",
        "                                                      num_labels=len(labels))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpeu096e88\n",
            "100%|██████████| 521/521 [00:00<00:00, 174930.55B/s]\n",
            "INFO:transformers.file_utils:copying /tmp/tmpeu096e88 to cache at /root/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
            "INFO:transformers.file_utils:removing temp file /tmp/tmpeu096e88\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /root/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
            "INFO:transformers.configuration_utils:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 8,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp0r0fvaex\n",
            "100%|██████████| 714314041/714314041 [00:14<00:00, 50520621.61B/s]\n",
            "INFO:transformers.file_utils:copying /tmp/tmp0r0fvaex to cache at /root/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
            "INFO:transformers.file_utils:removing temp file /tmp/tmp0r0fvaex\n",
            "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
            "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D64xl7q4gotq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3efa417-fbc0-4171-a7d5-db0e03337985"
      },
      "source": [
        "from transformers.data.processors.utils import InputExample\n",
        "from transformers.data.processors.glue import glue_convert_examples_to_features\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import torch.utils.data as data_utils\n",
        "import numpy as np \n",
        "\n",
        "BATCH_SIZE = 32\n",
        "MAX_SEQ_LEN = 128\n",
        "\n",
        "\n",
        "def select_field(features, field):\n",
        "  return [\n",
        "        [\n",
        "            feature[field]\n",
        "        ]\n",
        "        for feature in features\n",
        "    ]\n",
        "  \n",
        "def prepare_dataset(df):\n",
        "  df_sampl = df\n",
        "  sents = df_sampl['content'].values\n",
        "  labels = df_sampl['rating'].astype(int).values\n",
        "  labels_unique = df['rating'].astype(int).unique()\n",
        "  # print(labels_unique)\n",
        "  # print(labels)\n",
        "  # label_map = {i: i for i in range(11)}\n",
        "  guid =0 \n",
        "  input_examples = []\n",
        "  for sent, label in zip(sents, labels):\n",
        "    input_examples.append(InputExample(\n",
        "        guid, text_a=sent, text_b=None, label=label\n",
        "    ))\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  features = glue_convert_examples_to_features(\n",
        "      input_examples,\n",
        "      tokenizer=tokenizer,\n",
        "      max_length=MAX_SEQ_LEN,\n",
        "      output_mode='classification',\n",
        "      label_list = labels_unique\n",
        "  )\n",
        "\n",
        "\n",
        "  all_input_ids = torch.tensor([feature.input_ids for feature in features], dtype=torch.long)\n",
        "  all_input_mask = torch.tensor([feature.attention_mask for feature in features], dtype=torch.long)\n",
        "  all_segment_ids = torch.tensor([feature.token_type_ids for feature in features], dtype=torch.long)\n",
        "  all_label_ids = torch.tensor([feature.label for feature in features], dtype=torch.long)\n",
        "\n",
        "  dataset = TensorDataset(all_input_ids, \n",
        "                          all_input_mask, \n",
        "                          all_segment_ids, \n",
        "                          all_label_ids)\n",
        "  return dataset \n",
        "\n",
        "msk = np.random.rand(len(df)) < 0.8\n",
        "train = df[msk]\n",
        "test = df[~msk]\n",
        "train_datatset = prepare_dataset(train)\n",
        "test_dataset = prepare_dataset(test)\n",
        "train_dataloader = data_utils.DataLoader(train_datatset, \n",
        "                                         batch_size=BATCH_SIZE, \n",
        "                                         shuffle=True)\n",
        "test_dataloader = data_utils.DataLoader(test_dataset, \n",
        "                                        batch_size=BATCH_SIZE, \n",
        "                                        shuffle=True)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "INFO:transformers.data.processors.glue:Writing example 0\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 10190 42185 10157 14552 10418 11033 18775 100711 14950 10104 11710 33504 117 76206 68782 16600 73264 10280 83366 10692 177 11342 17894 10797 53873 31519 11335 10132 45840 12354 78098 50545 15088 41152 31167 40574 17249 20149 28978 10147 14909 10113 14042 187 14660 10162 25651 19648 24831 10174 119 10685 61048 20868 10963 27966 88629 60914 73837 187 13342 22555 27302 175 81349 88077 10644 87468 52214 20157 23462 10219 11133 12518 39860 38356 44762 10113 10149 28780 98685 20506 19180 65993 10116 117 17677 10339 71272 11614 47136 10132 57437 57971 117 11951 65190 18485 59763 10157 11951 191 12294 28395 186 10963 10419 119 38217 46944 107 140 15803 49126 11043 107 100 42141 20909 52465 10219 62701 15688 62061 183 348 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 7 (id = 0)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 11936 11913 10157 42845 107 81526 11080 10138 107 13484 49495 172 14548 10449 54488 12764 119 160 12644 17479 11048 13717 96725 10963 20157 19579 59726 86828 45637 11037 56773 42662 183 28731 18545 131 10311 99127 177 23900 10116 11048 91288 10514 11438 10870 28731 18545 191 17993 10269 10132 70367 46458 119 81526 106212 13342 10424 191 12741 10514 25197 11297 11058 20084 84966 10149 370 107213 10269 32221 14590 10644 11887 35345 28070 13050 76886 10113 14327 11195 23531 113 10458 107 23789 26477 370 107213 107 114 117 169 36633 191 46458 194 11284 12547 15549 89572 113 107 94566 10113 177 10741 23090 104536 117 177 28731 18545 107 114 119 91664 38508 10171 13020 117 27213 101612 11348 117 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 5 (id = 1)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 19803 10320 12110 25691 117 169 10741 65506 10756 10399 11140 23202 25474 101367 10644 11058 11264 10598 10132 63085 119 155 20129 10500 66284 10756 191 30031 36867 10870 117 191 10157 95312 370 52465 20034 194 19556 95830 30582 39108 10138 83617 10206 10339 44092 80534 10132 330 15149 10269 43705 52474 10138 107 10117 10287 57218 107 13055 17249 18795 10335 64199 13762 108603 19758 119 106482 19579 10157 61312 32374 28702 12240 40670 14260 10801 10506 183 14052 101601 10269 27836 71971 11202 93410 10157 10493 10425 22427 15636 30823 119 160 51902 18910 11153 10269 191 16889 10157 84921 10342 11048 71259 11669 65551 10113 10925 10113 25474 101367 10113 20506 19180 13739 15577 10339 16828 11039 32298 10824 13342 177 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 7 (id = 0)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 13796 17272 25129 15791 10458 183 11474 56862 10138 117 194 42923 58452 16559 191 10149 17777 10853 11048 86078 10113 170 108050 12419 74743 10133 191 187 12294 11044 10418 70625 177 17339 15460 23922 11058 50014 62208 49775 12457 107140 13969 83981 136 11469 11058 53032 37522 10424 22278 30281 119 138 14330 106 107 11474 56862 119 158 67603 10147 10953 68216 107 69048 55260 65355 22491 10114 18996 20589 10238 44743 117 15259 100 11170 14052 24710 26673 194 11161 89691 39709 11159 21791 100 10132 109687 10400 10266 25125 107140 13969 191 35327 60519 13906 17414 12892 10381 107 13214 91782 10133 16179 10113 107 119 20304 19605 12754 117 21083 170 108050 10157 14004 99486 10451 117 10311 68470 73121 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 8 (id = 2)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 28941 19986 11485 59763 10113 194 12644 107 25879 31609 107066 107 119 155 10870 20868 75511 10149 37403 177 191 62764 70389 10229 13050 10458 117 10824 54421 10526 177 27573 117 24779 22422 12555 10537 47136 191 11322 10451 12402 31119 10116 194 174 24831 80761 177 16334 27275 10147 119 160 61062 17272 117 55711 10403 10305 117 191 10284 17837 17272 183 17771 191 11342 40321 11284 15340 15274 10123 117 10155 17339 11950 23090 11484 19867 103233 10112 10424 45101 10506 100 169 13055 96825 17470 119 107 25879 31609 25901 11717 107 19457 47339 93858 10149 191 10157 26336 15577 57814 12837 18795 10514 53906 13311 61657 10644 11639 22444 11033 16066 28773 10149 51995 29093 80193 59676 11530 10220 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 2 (id = 3)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2012 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1010 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2152 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (997 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (933 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (979 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (997 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1020 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2107 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1006 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1805 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1825 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1433 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1016 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1013 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1679 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1021 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1936 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1973 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1901 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1456 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2086 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2123 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2180 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1006 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (994 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1984 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (901 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (931 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2210 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2137 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1799 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1010 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1340 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2304 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (863 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1796 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (921 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2425 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1915 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2063 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1708 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2447 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2001 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1884 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1714 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1921 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1775 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2682 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1920 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "INFO:transformers.data.processors.glue:Writing example 0\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 25879 10143 75911 10112 10424 194 15577 15026 119 50690 11484 107 23318 14639 11484 12318 20482 107 33705 12547 10972 194 69191 45868 48889 10418 101263 11477 113 10183 119 107 104402 107 114 117 172 14548 10390 87468 71663 57577 20935 10963 194 107 46527 107 177 13173 11133 53569 172 14548 10874 99710 11950 50302 13762 36867 18811 53895 10147 194 107 28248 117 13749 10113 107 117 10114 191 88781 10147 73006 10514 20994 44336 81225 10339 191 14950 95113 43327 50302 26127 11335 27980 119 20304 19605 64671 21791 10138 55493 11877 103944 10116 23762 69625 24948 62026 10963 16600 10797 19195 36674 14052 24710 11484 18933 18840 46152 10238 89850 75840 131 37039 113 12947 10340 114 13595 11297 59230 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 3 (id = 0)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 20304 19605 12754 98637 85172 10483 19325 10339 10457 13342 81669 11133 191 10207 10395 55493 11877 12059 40377 10116 107 10281 85699 10500 105999 104305 107 117 15259 14052 77578 13342 12361 181 119 10106 119 29553 81613 10132 11193 12223 11221 27207 10129 12197 39158 10284 91761 10797 18788 10360 21757 95830 30582 16096 88669 105337 11162 15892 119 25444 93387 85351 194 16262 70974 10806 12547 13040 183 10794 15490 93744 24813 33043 117 183 34506 20974 18996 23243 47136 68914 117 41303 12412 39158 69346 31317 172 14548 14660 27932 10149 54949 10891 25901 181 119 10106 119 11048 153 19088 11565 119 107 155 77008 107 118 11499 59880 100162 66998 16326 75327 41443 11342 48850 101115 10116 14052 13520 15577 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 7 (id = 1)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 27622 24676 10129 117 13680 10149 36770 53569 10424 117 12537 10824 75980 10637 58687 10305 12589 177 90405 10293 23090 119 141 14548 10874 49876 14916 39131 12920 10149 27648 10701 11284 37134 46101 10371 117 17677 117 23774 18933 20157 19579 44336 19669 10132 11484 76300 117 12132 26127 10113 23040 48726 184 57731 10219 20400 10797 63971 191 72855 16727 40365 10424 32650 12680 20157 10870 27966 18599 12294 46267 37863 100711 16602 37042 10116 22620 10237 194 33106 10133 29148 39108 10644 119 156 18558 67299 18762 91929 14083 10368 117 13680 75511 191 90217 194 31409 10549 10853 12547 97854 50284 191 20728 19139 21931 39895 89232 119 21946 26461 93147 117 17677 10824 10132 19642 14194 10853 194 33106 10133 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 6 (id = 2)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 369 10157 12097 191 23040 10963 85942 11877 10973 13050 53873 14660 38967 27169 191 79459 16379 16646 78129 23090 119 13744 32762 40212 10963 117 194 57117 62764 13177 10147 120 107626 13711 117 13680 10104 11710 53569 183 76456 58123 96716 10112 177 12644 117 13050 10973 10135 191 20935 16131 16559 119 140 10305 14660 17761 10644 330 40708 24390 10941 66768 26601 23040 10963 12547 191 104406 47929 14950 82927 10644 117 10514 25197 11297 10127 49295 10238 117 191 53549 52465 109702 14330 33694 10238 117 59676 32221 11679 10238 10149 28729 24710 23153 16640 46607 18139 119 160 99346 20710 10400 12741 10114 46845 191 62764 70389 99676 191 183 25135 10269 71051 10157 107 155 20129 34582 13993 14950 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 7 (id = 1)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 512). Running this sequence through the model will result in indexing errors\n",
            "INFO:transformers.data.processors.glue:*** Example ***\n",
            "INFO:transformers.data.processors.glue:guid: 0\n",
            "INFO:transformers.data.processors.glue:input_ids: 101 66161 72180 64363 194 36284 11058 11342 66734 10144 58841 119 23319 76684 13050 172 37231 10133 10424 10114 191 107 60781 16445 107 117 12412 13717 23090 29019 10147 172 14548 10284 117 70908 10483 10424 10311 12947 11257 43573 10514 53482 177 66998 11140 10644 10132 175 98413 30980 10621 12796 35779 117 34492 15444 15127 54913 64417 11484 12947 10339 186 10963 18371 119 107 105822 97033 10644 107 10114 15791 194 23453 23685 15926 13078 76711 10551 24130 117 191 20069 10183 84575 13969 29643 25032 10514 16112 64802 33518 10644 11147 12110 18933 108593 91611 10144 73134 10112 100 169 29836 14515 11322 10963 19025 11680 105607 10157 16600 19003 12110 15155 26336 191 12682 20954 119 39397 23774 11530 18643 102\n",
            "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:transformers.data.processors.glue:label: 4 (id = 3)\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (949 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2042 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2134 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1832 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1772 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1651 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1956 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1713 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1846 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2129 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (949 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2161 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (979 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2424 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2124 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn4SXhD7qziZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW, WarmupLinearSchedule\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "lr = 2e-5\n",
        "warmup=0.1\n",
        "\n",
        "max_grad_norm = 1.0\n",
        "num_total_steps = 1000\n",
        "num_warmup_steps = 100\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
        "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)  # PyTorch scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5ncBAcBtxNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "367e0382-5bfe-48be-982d-476418ca25cf"
      },
      "source": [
        "from tqdm import trange \n",
        "### and used like this:\n",
        "# for batch in train_data:\n",
        "#     loss = model(batch)\n",
        "#     loss.backward()\n",
        "#     torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore (so you can use amp without issue)\n",
        "#     optimizer.step()\n",
        "#     scheduler.step()\n",
        "#     optimizer.zero_grad()\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "EPOCHS_NUM = 4\n",
        "loss_history = []\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name,\n",
        "                                                      num_labels=len(labels))\n",
        "model.cuda()\n",
        "\n",
        "for epoch in trange(EPOCHS_NUM, desc='EPOCH'):\n",
        "  # set to training mode\n",
        "  model.train()\n",
        "  total_loss =0\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_segment_ids, b_labels = batch\n",
        "    outputs = model(b_input_ids, \n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "    loss = outputs[0]\n",
        "    loss_history.append(loss.item())\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore (so you can use amp without issue)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss += loss.item()\n",
        "  print(f\"Total loss is {total_loss}\")\n",
        "\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps = 0\n",
        "  for batch in test_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_segment_ids, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask)[0]\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /root/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
            "INFO:transformers.configuration_utils:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 10,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
            "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "\n",
            "\n",
            "EPOCH:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total loss is 36.77368211746216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "EPOCH:  25%|██▌       | 1/4 [00:23<01:11, 23.71s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.30568181818181817\n",
            "Total loss is 36.796571493148804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "EPOCH:  50%|█████     | 2/4 [00:47<00:47, 23.69s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.3176136363636364\n",
            "Total loss is 36.829204082489014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "EPOCH:  75%|███████▌  | 3/4 [01:11<00:23, 23.68s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.3534090909090909\n",
            "Total loss is 36.76258611679077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "EPOCH: 100%|██████████| 4/4 [01:34<00:00, 23.68s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.34147727272727274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KHiDH1qY1B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}