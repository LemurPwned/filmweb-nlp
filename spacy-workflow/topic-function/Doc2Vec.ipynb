{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, OrderedDict, defaultdict\n",
    "import gensim.utils \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import logging\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from random import sample\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "review_file = \"/Users/jakubmojsiejuk/Documents/agh/filmweb-nlp/reviews_for_bert*.csv\"\n",
    "\n",
    "reviews = pd.DataFrame()\n",
    "for rev_file in glob.glob(review_file):\n",
    "    r = pd.read_csv(rev_file)\n",
    "    reviews = pd.concat([reviews, r])\n",
    "    \n",
    "reviews = reviews.loc[(reviews['rating'] <= 3) | (reviews['rating'] >= 8)]\n",
    "# msk = np.random.rand(len(radical_reviews)) < 0.7\n",
    "# radical_reviews['sent'] = radical_reviews['rating'].apply(lambda x: 'pos' if x > 5 else 'neg')\n",
    "# X_train, y_train = radical_reviews['content'][msk].tolist(), radical_reviews['sent'][msk].tolist()\n",
    "# X_test, y_test = radical_reviews['content'][~msk].tolist(), radical_reviews['sent'][~msk].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_RATIO = 0.7\n",
    "\n",
    "def create_sentiment_document(review):\n",
    "    split = 'train' if np.random.rand() < TRAIN_TEST_RATIO else 'test'\n",
    "    index = review.id\n",
    "    sentiment = int(review['rating'] > 5)\n",
    "#     sentiment = review['rating']\n",
    "    tokens = gensim.utils.to_unicode(review['content']).split()\n",
    "    return SentimentDoc(tokens, [index], split, sentiment)\n",
    "\n",
    "\n",
    "reviews['id'] = range(1, len(reviews)+1)\n",
    "SentimentDoc = namedtuple('sentiment_doc', 'words tags split sentiment')\n",
    "\n",
    "reviews['docs'] = reviews.apply(create_sentiment_document, axis=1)\n",
    "\n",
    "\n",
    "# msk = np.random.rand(len(reviews)) < TRAIN_TEST_RATIO\n",
    "# train = reviews['docs'][msk].tolist()\n",
    "# test = reviews['docs'][~msk].tolist()\n",
    "all_docs = reviews['docs'].tolist()\n",
    "train_docs = [doc for doc in all_docs if doc.split == 'train']\n",
    "test_docs = [doc for doc in all_docs if doc.split == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945 413 1358\n"
     ]
    }
   ],
   "source": [
    "print(len(train_docs), len(test_docs), len(all_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d200,n5,hs,mc15,t8) vocabulary scanned & state initialized\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8) vocabulary scanned & state initialized\n",
      "Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8) vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "source": [
    "common_kwargs = dict(\n",
    "    vector_size=200, epochs=30, min_count=15,\n",
    "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=1,\n",
    ")\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, **common_kwargs),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, window=10, alpha=0.05, comment='alpha=0.05', **common_kwargs),\n",
    "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
    "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, window=5, **common_kwargs),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "    model.build_vocab(all_docs)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[1]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def logistic_predictor_from_data(train_targets, train_regressors):\n",
    "    \"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\n",
    "    logit = sm.Logit(train_targets, train_regressors)\n",
    "    try:\n",
    "        predictor = logit.fit(disp=0, method='bfgs')\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR encountered {e}\")\n",
    "        print(train_targets)\n",
    "        return None\n",
    "#     print(predictor.summary())\n",
    "    return predictor\n",
    "\n",
    "def multinomial_predictor_from_data(train_targets, train_regressors):\n",
    "    \"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\n",
    "    clf = LogisticRegression(random_state=-0).fit(train_targets, train_regressors)\n",
    "    return clf \n",
    "#     logit = sm.MNLogit(train_targets, train_regressors)\n",
    "#     try:\n",
    "#         predictor = logit.fit(disp=0, method='bfgs')\n",
    "#     except Exception as e:\n",
    "#         print(f\"ERROR encountered {e}\")\n",
    "#         print(train_targets)\n",
    "#         return None\n",
    "# #     print(predictor.summary())\n",
    "#     return predictor\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets = [doc.sentiment for doc in train_set]\n",
    "    train_regressors = [test_model.docvecs[doc.tags[0]] for doc in train_set]\n",
    "    train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_set]\n",
    "    test_regressors = sm.add_constant(test_regressors)\n",
    "\n",
    "#     if predictor is None:\n",
    "#         return (1.0, len(test_regressors), len(test_regressors), None)\n",
    "    \n",
    "#     Predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "#     p = np.rint(test_predictions)\n",
    "#     clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=200, penalty='l1',\n",
    "#                              multi_class='multinomial').fit(train_regressors, train_targets)\n",
    "#     print(clf.score(train_regressors, train_targets))\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_set])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec(dbow,d200,n5,hs,mc15,t8)\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d200,n5,hs,mc15,t8)\n",
      "\n",
      "0.184019 Doc2Vec(dbow,d200,n5,hs,mc15,t8)\n",
      "\n",
      "Training Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8)\n",
      "\n",
      "0.259080 Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8)\n",
      "\n",
      "Training Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8)\n",
      "\n",
      "0.370460 Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8)\n",
      "\n",
      "\n",
      "Evaluating complex Doc2Vec(dbow,d200,n5,hs,mc15,t8)+Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.246973 Doc2Vec(dbow,d200,n5,hs,mc15,t8)+Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8)\n",
      "\n",
      "\n",
      "Evaluating complex Doc2Vec(dbow,d200,n5,hs,mc15,t8)+Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8)\n",
      "\n",
      "0.208232 Doc2Vec(dbow,d200,n5,hs,mc15,t8)+Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "error_rates = defaultdict(lambda: 1.0) \n",
    "\n",
    "from random import shuffle\n",
    "shuffled_alldocs = all_docs[:]\n",
    "shuffle(shuffled_alldocs)\n",
    "\n",
    "for model in simple_models:\n",
    "    print(\"Training %s\" % model)\n",
    "    model.train(shuffled_alldocs, total_examples=len(shuffled_alldocs), epochs=model.epochs)\n",
    "\n",
    "    print(\"\\nEvaluating %s\" % model)\n",
    "    err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    print(\"\\n%f %s\\n\" % (err_rate, model))\n",
    "\n",
    "for model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]:\n",
    "    print(\"\\nEvaluating complex %s\" % model)\n",
    "    err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    print(\"\\n%f %s\\n\" % (err_rate, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err_rate Model\n",
      "0.184019 Doc2Vec(dbow,d200,n5,hs,mc15,t8)\n",
      "0.208232 Doc2Vec(dbow,d200,n5,hs,mc15,t8)+Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8)\n",
      "0.246973 Doc2Vec(dbow,d200,n5,hs,mc15,t8)+Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8)\n",
      "0.259080 Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8)\n",
      "0.370460 Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Err_rate Model\")\n",
    "for rate, name in sorted((rate, name) for name, rate in error_rates.items()):\n",
    "    print(\"%f %s\" % (rate, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 16...\n",
      "Doc2Vec(dbow,d200,n5,hs,mc15,t8):\n",
      " [(17, 0.9894669055938721), (3223, 0.30570924282073975), (230, 0.3021594285964966)]\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d200,n5,hs,w10,mc15,t8):\n",
      " [(17, 0.95763099193573), (1876, 0.3645714223384857), (4726, 0.3634454607963562)]\n",
      "Doc2Vec(dm/c,d200,n5,hs,w5,mc15,t8):\n",
      " [(17, 0.9145972728729248), (1232, 0.2573408782482147), (2882, 0.2285965383052826)]\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # Pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "for model in simple_models:\n",
    "    inferred_docvec = model.infer_vector(all_docs[doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (3146): «\"Green Hornet 3D\" to filmowy hołd złożony wszystkim tym, którzy nie chcą dorosnąć, którzy marzą o niesamowitych przygodach, bohaterskich wyczynach i zabawkach od których włosy staną dęba. Zamiast standardowej adaptacji komiksu twórcy postanowili zrobić film fanowski i o fanach, zarazić widzów entuzjazmem do kolorowych historyjek, które rozbudzają wyobraźnię milionów chłopców na całym świecie. Ogólny zarys fabuły jest rzecz jasna wzięty z komiksu o Zielonym Szerszeniu. Brit Reid jest zepsutym dziedzicem medialnej fortuny, dla którego życie to jedna, nieustająca balanga. Zmienia się to, kiedy jego ojciec umiera w wyniku reakcji uczuleniowej na pszczeli jad. Wtedy Brit poznaje mechanika ojca, Kato, w którym odnajduje bratnią duszę. Razem wyruszają nocą na wyprawę, która ma być dziecinnym dowcipem, a kończy się narodzinami superbohatera udającego superzłoczyńcę. Panowie nie wzięli pod uwagę, że ta posada jest już zajęta, co będzie miało swoje brutalnie bolesne konsekwencje. \"Green Hornet 3D\" ma konstrukcję typowego komiksu z jasnym podziałem ról. Seth Rogen i Evan Goldberg są jego scenarzystami, zaś Michel Gondry ilustratorem. Stąd też film w warstwie fabularnej przypomina \"Boski chillout\" i \"Supersamca\". Jest zatem komedią kumpelską o dwóch niedojrzałych facetach, którzy wciąż bawią się jak dzieci, tylko ich zabawki są nieco większe i bardziej niebezpieczne. Pełno jest tu gagów, świetnych dialogów, ciętych ripost i przezabawnych epizodów (James Franco). Ci, którzy dobrze bawili się na poprzednich filmach Rogena i Goldberga mogą iść w ciemno, na pewno się nie zawiodą. Rola Gondry'ego jest w tym filmie tylko drugoplanowa. W fabule nie znajdziecie prawie niczego, po czym można byłoby rozpoznać, że to jego dzieło. Swoje piętno odcisnął w warstwie wizualnej. Niektóre sekwencje (pierwsza walka Kato, rozprzestrzenianie się informacji o nagrodzie za Szerszenia) to majstersztyki, w których widać teledyskowy rodowód Gondry'ego. Niestety ponieważ Gondry z wielką precyzją przygotowywał każde ujęcie, fani 3D mogą wychodząc z kina czuć pewien niedosyt. Widać bowiem, że reżyser kręcił całość z myślą o 2D, co nie zawsze dało się w procesie konwersji zamaskować. Na szczęście Rogen i Jay Chou szaleją na ekranie, zapewniając wystarczająco dużo rozrywki. Barwną postać wykreował również Christoph Waltz. Jego Chudnowski/Bloodnowski jest swoistą parodią roli w \"Bękartach wojny\". Całość ma lekki, niezobowiązujący charakter. Jest zabawą, która wszystkim wiecznym chłopcom przypadnie do gustu.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/c,d100,n5,w5,mc2,t8):\n",
      "\n",
      "MOST (3061, 0.9243475198745728): «Jak najłatwiej zdobyć serca Francuzów? Oczywiście wychwalając ich kraj z Paryżem na czele. Woody Allen nie musiał tego robić, by jego film został zaproszony do otwarcia Festiwalu w Cannes. A jednak wydaje się, że \"Midnight in Paris\" powstało przede wszystkim jako sentymentalna ilustracja tego, co wie każdy amerykański turysta na \"Czamps Elajsis\": że Paryż miejscem magicznym jest. Gil (Owen Wilson, w swojej roli trochę zbyt nachalnie naśladujący Allena) to początkujący pisarz kochający się w przeszłości. Niepoprawny romantyk, jak na każdym kroku podkreśla jego narzeczona Inez (Rachel McAdams), skoncentrowana raczej na pozorach i konkretach, takich jak przygotowania do wesela. Para spędza wakacje w stolicy kochanków głównie w towarzystwie rodziców dziewczyny oraz zaprzyjaźnionej pary innych Amerykanów z wyższej klasy średniej. Ich czas jest obity pluszem – klasyczne allenowskie konwersacje odbywają w przepysznych hotelowych wnętrzach, urokliwych zaułkach, na targach staroci itp. Komediowych akcentów dostarcza nieznośnie elokwentny Paul, które najprzyjemniejszy spacer potrafi zepsuć Gilowi akademickimi dywagacjami, na przykład na temat starofrancuskiego znaczenia słowa \"Wersal\". W końcu pisarz odłącza się od grupy, a o północy zostaje zabrany przez grupkę rozbawionych kawalerów do lat 20., w sam środek paryskiej bohemy: poznaje Scotta Fitzgeralda, Ernesta Hemingwaya, Gertrudę Stein, Pabla Picasso, Luisa Bunela... Czy długo da się żyć w tym złudzeniu? Przez chwilę wraz z bohaterem będzie nam się wydawać, że i owszem: bo Gil czuje się jak ryba w wodzie wśród wyborowego towarzystwa. Nie dość, że Stein pomaga mu w pracy nad powieścią, a Hemingway udziela życiowych rad (scena, gdy mówi o męskim odwadze, jest wyśmienita), to zadurza się w muzie malarzy, Adriannie (Marion Cotillard). Kilka żartów wynikających z podróży w czasie naprawdę się udało, jak ten, gdy bohater poddaje Bunuelowi pomysł na \"Anioła zagłady\", który reżyser uznaje za trochę głupawy. Na marginesie musimy jednak odnotować, że monotonnie wypada, z założenia śmieszne, przedstawianie bohaterowi wybitnych ludzi epoki: Wilson za każdym razem, gdy spotyka podziwianego artystę, serwuje nam minę, którą chyba chciał wygrać casting na jelonka Bambi. Allen nie sfilmował wycieczek bohatera w przeszłość w najbardziej oczywisty sposób: nie użył stylistycznych klisz przeznaczonych dla sekwencji sennych. W ogóle w żaden sposób nie odróżnił ich wizualnie od tego, co dzieje się \"naprawdę\". Bo przecież obraz Paryża współczesnego w tym filmie również jest kompletnie nierealistyczny. To stereotyp wcielony, miasto takie, jakim chcą je postrzegać turyści, co przebiegły reżyser sygnalizuje nam już na wstępie, rozpoczynając opowieść od serii ujęć z najbardziej rozpoznawalnych paryskich miejsc, oklepanych do bólu widoczków miasta. Więc dlaczego nie odczytujemy tego filmu jako czystego kiczu, romantycznej komedyjki o \"najbardziej romantycznym mieście świata\"? Tylko dlatego, że aż nazbyt dobrze znamy starego Allena. Nie potraktujemy go do końca serio, gdy pokazuje nam parę kochanków spacerujących w scenografii ściągniętej z obrazu Moneta \"Nenufary\", przecież musiał ukryć dla nas jakieś głębsze znaczenia. Przy takim nastawieniu \"Midnight...\" będzie opowieścią o amerykańskim wyobrażeniu Paryża, o oscylowaniu pomiędzy rzeczywistością a marzeniem itp. A gdyby ktoś inny zrobił ten film? Chyba nie szukalibyśmy równie daleko idących interpretacji. Gdy wieczorna projekcja w pałacu festiwalowym dobiegła końca, widownia zaczęła klaskać w rytmie kankana, który towarzyszy napisom – jak duża wycieczka zadowolonych z siebie turystów w Moulin Rouge. W tym momencie utwierdziłam się w przekonaniu, że gra Allena z kiczem okazała się w \"Midnight...\" nazbyt niebezpieczna, że poszedł za daleko w romansie z nim i w końcu wpadł w jego sidła. Stworzył przede wszystkim (nieznośnie) lekką opowiastkę o przygodach pewnego Amerykanina w wyobrażonym Paryżu. Odnajdziemy tu elementy dawnych obsesji i przemyśleń reżysera, ale w ilości śladowej. Mruga do nas okiem tak intensywnie, że że od tego mrugania musiał w końcu dorobić się zaćmy.»\n",
      "\n",
      "MEDIAN (2021, -0.012294255197048187): «Tygrysy tasmańskie, zwane pieszczotliwie Tazzies, wyginęły w latach trzydziestych ubiegłego wieku. Przybywający na wyspę Europejczycy tępili te zwierzęta ze względu na ich drapieżny charakter – ich ofiarami padały głównie małe zwierzęta hodowlane. W \"Łowcy\" Daniela Nettheima ostatni z tygrysów tasmańskich trafia między muszkę a szczerbinkę przedstawiciela innego, wymierającego gatunku – introwertycznych twardzieli o gołębim sercu, których kino uwielbia prawie tak samo jak majestatyczną i obojętną naturę. Willem Dafoe Magnolia Pictures Martin David (Willem Dafoe), jak każdy najemnik, nie zadaje zbędnych pytań. Gdy potężna wojskowa kompania biotechnologiczna zatrudnia go w celu wytropienia drapieżnika, pobrania próbek DNA i eliminacji z łańcucha pokarmowego, bohater po prostu zarzuca karabin na ramię, myślami będąc już przy bankowym okienku. Lecz już po kilku chwilach spędzonych razem z Martinem w oplecionym gęstymi lasami i górzystymi pasmami miasteczku, domyślamy się, że ta misja nie będzie kaszką z mleczkiem. Przykrywka bohatera (pojawia się on na tasmańskiej prowincji incognito, jako uniwersytecki biolog) staje się płachtą na rozjuszonych mieszkańców, którzy prowadzącą partyzancką wojenkę z blokującymi drogi ekologami, chciwa korporacja trzyma Martina na krótkiej smyczy, zaś na stancji z tęsknoty usychają żona i dzieci jednego z miejscowych farmerów – mężczyzna wyruszył na spotkanie z tygrysem i ślad po nim zaginął. Impresjonistyczna opowieść o człowieku biorącym się za bary z przyrodą splecie się od tego momentu z obrazem o samotności jako podstawowym uczuciu definiującym człowieczeństwo. Morgana Davies, Frances O'Connor Magnolia Pictures Milcząca natura wydaje się drwić z obładowanego gadżetami, mapami i pułapkami myśliwego. Reżyser podgląda ją w skupieniu, ale nie czyni z tego aktu nabożeństwa: sekwencje, w których bohater rozpala ogień, rozkłada pułapki i inicjuje kolejne myśliwskie rytuały, to w obiektywie Nettheima ascetyczne, surowe kino. Zamaszyste panoramy rodem z filmów fantasy rozprężają nieco tę kameralną aurę, a \"Łowca\" balansuje cały czas na granicy intymności i kina epickiego – zarówno pod względem formalnym, jak i tematycznym: na fundamentach filmowego konfliktu Werner Herzog wzniósłby ze dwie fabuły i trzy dokumenty. Stylistyczna oszczędność i narracyjna równowaga to zresztą największe cnoty filmu. Obraz jest \"wychłodzony\", reżyser nie ulega pokusie zrobienia z Martina bohatera tragicznego, zaś sam konflikt – oczywiście, bohater narazi w końcu swój kontrakt dla wegetujących dzieciaków i ich matki – rozgrywa się bez zbędnych, melodramatycznych uniesień. Willem Dafoe, Sam Neill Magnolia Pictures W te same struny uderza kapitalny Willem Dafoe. To może być jego najlepsza rola od lat (podobnie zresztą jak drugoplanowy występ neurotycznej Frances O’Connor). Skupiony, powściągliwy, rozważnie korzystający ze swojego mimicznego arsenału, przekonuje zarówno jako zmęczony życiową rutyną samotnik, jak i wrażliwy facet, spełniający się w charakterze zastępczego ojca. Całość powstała na kanwie powieści Julii Leigh, która w 1999 roku rozbiła bank i zgarnęła szereg prestiżowych nagród. I choć metaforyczny, nieco mroczniejszy styl autorki (piszącej o ciemności, która w głuszy \"rozdziera szaty i wkrada się w nas wszystkimi otworami\") został stonowany, Nettheim udowodnił tym zabiegiem, że gdy przychodzi do adaptacji, respekt i strach to dwie różne rzeczy. Koniec końców, przepisał \"Łowcę\" swoim charakterem pisma i okazał się autorem filmowym z prawdziwego zdarzenia.»\n",
      "\n",
      "LEAST (745, -0.89349764585495): «\"Athadu - Poszukiwany\" to kolejna propozycja kina indyjskiego. Tym razem jednak nie z Bollywood, a z siostrzanego Tollywood. Dla nas w Polsce różnica żadna, a i w Indiach poza językiem i nieco skromniejszymi budżetami trudno jest je od siebie odróżnic. Obraz Trivikrama Srinivasa w Polsce można jednak polecić jedynie osobom już znającym kino hinduskie. Jest to bowiem produkcja bardzo typowa dla tamtejszej kinematografii, co oznacza, że neofitów może zdumieć swoją naiwnością i nagromadzeniem nieprawdopodobieństw. Bohaterem filmu jest Nandu, wychowany przez ulicę, teraz zajmujący się mordowaniem na zlecenie. Jego najnowsze zadanie to sfingowanie zamachu na szefa partii, która ostatnio ignorowana jest przez wyborców. Zamach ma pomóc partii wygrać w nadchodzących wyborach. Coś jednak poszło nie tak, szef partii ginie naprawdę, a Nandu jest ścigany przez policję. W pociągu spotyka mężczyznę, który po latach zamierza wrócić do domu. Niestety mężczyzna ten ginie, co Nandu skrzętnie wykorzystuje, przyjmując jego tożsamość. W ten oto sposób zyska rodzinę, której nigdy nie miał i miłość, o której nawet nie śmiał marzyć. Film zrobiony jest z dużym rozmachem, ale nie może równać się z superprodukcjami z Bombaju. Całość jest bardzo konserwatywna, jeśli chodzi o pokazanie relacji męsko-damskich, a piosenki i kolejne punkty kulminacyjne są realizowane podług sprawdzonego klucza. Czyni to z \"Athadu\" bardzo dobrą rozrywkę, pod warunkiem, że widz wie, czego się spodziewać i nie lubi być zaskakiwany formalnymi eksperymentami. Piosenki są rytmiczne i łatwo wpadają w ucho. Choreografia niewyszukana, ale bohaterowie pokazani są w sposób sympatyczny i przez to bliscy widzom. Niestety taka konstrukcja \"Athadu\" ma też swoje wady, które sprawiają, że film nie należy pokazywać osobom mało doświadczonym z Bollywood (czy Tollywood). Logika narracji w wielu momentach szwankuje. Potrzeba wzbudzenia określonych emocji sprawia, że sceny są naiwne bądź ledwie zarysowane. Widz przyzwyczajony do zachodniego realizmu, będzie ze zdumieniem kręcił głową i politowaniem patrzył na każdego, kto stwierdzić po obejrzeniu \"Atrhadu\", że kino hinduskie to świetna rozrywka. Obraz Trivikrama Srinivasa z czystym sumieniem mogę polecić jedynie zatwardziałym fanom Tollywood. To film zrobiony specjalnie dla was, co z całą pewnością docenicie.»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # pick random doc, re-run cell for more examples\n",
    "model = random.choice(simple_models)  # and a random model\n",
    "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)  # get *all* similar documents\n",
    "print(u'TARGET (%d): «%s»\\n' % (doc_id, ' '.join(all_docs[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    s = sims[index]\n",
    "    i = sims[index][0]\n",
    "    words = ' '.join(all_docs[i].words)\n",
    "    print(u'%s %s: «%s»\\n' % (label, s, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_word: 'wszelką' model: Doc2Vec(dbow,d100,n5,mc2,t8) similar words:\n",
      "    1. 0.43 'ludzie:'\n",
      "    2. 0.41 'zamknięty'\n",
      "    3. 0.40 'określili),'\n",
      "    4. 0.38 '(MGM)Screen'\n",
      "    5. 0.38 '9.'\n",
      "    6. 0.38 'świętej'\n",
      "    7. 0.38 'Zawstydzony'\n",
      "    8. 0.38 'szukasz'\n",
      "    9. 0.38 'dryfującym'\n",
      "    10. 0.37 'rozróba'\n",
      "\n",
      "target_word: 'wszelką' model: Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t8) similar words:\n",
      "    1. 0.61 'cenę'\n",
      "    2. 0.50 'zapłacić'\n",
      "    3. 0.48 'odpowiedzialność'\n",
      "    4. 0.47 'przestrzec'\n",
      "    5. 0.47 'młodu'\n",
      "    6. 0.46 'kraty'\n",
      "    7. 0.46 'sądem'\n",
      "    8. 0.46 'stylizację,'\n",
      "    9. 0.46 'karę'\n",
      "    10. 0.44 'uchronić'\n",
      "\n",
      "target_word: 'wszelką' model: Doc2Vec(dm/c,d100,n5,w5,mc2,t8) similar words:\n",
      "    1. 0.72 'nieudolną'\n",
      "    2. 0.70 'granicą'\n",
      "    3. 0.69 'efektowną,'\n",
      "    4. 0.69 'dobrą'\n",
      "    5. 0.69 'fasadą'\n",
      "    6. 0.68 'sprayem'\n",
      "    7. 0.68 'wiktoriańską'\n",
      "    8. 0.67 'sprzeniewierzonymi'\n",
      "    9. 0.67 'dotykiem,'\n",
      "    10. 0.67 'cudzą'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "word_models = simple_models[:]\n",
    "\n",
    "def pick_random_word(model, threshold=10):\n",
    "    # pick a random word with a suitable number of occurences\n",
    "    while True:\n",
    "        word = random.choice(model.wv.index2word)\n",
    "        if model.wv.vocab[word].count > threshold:\n",
    "            return word\n",
    "\n",
    "target_word = pick_random_word(word_models[0])\n",
    "# or uncomment below line, to just pick a word from the relevant domain:\n",
    "# target_word = 'comedy/drama'\n",
    "\n",
    "for model in word_models:\n",
    "    print('target_word: %r model: %s similar words:' % (target_word, model))\n",
    "    for i, (word, sim) in enumerate(model.wv.most_similar(target_word, topn=10), 1):\n",
    "        print('    %d. %.2f %r' % (i, sim, word))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
